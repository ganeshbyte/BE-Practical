{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ganesh\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the dataset\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Boston Housing dataset\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n",
      " 'B' 'LSTAT']\n"
     ]
    }
   ],
   "source": [
    "# feature names of boston dataset\n",
    "feature_names = boston.feature_names\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Build the model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Create a Sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# Add multiple Dense layers\n",
    "model.add(Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1))  # Output layer, no activation for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 2ms/step - loss: 601.2278 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18b71e17100>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train the model\n",
    "model.fit(X_train_scaled, y_train, epochs=1, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 520.3526 - accuracy: 0.0000e+00\n",
      "Test Loss: 520.3526000976562 0.0\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Evaluate the model\n",
    "loss, acc = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Loss: {loss} {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19870265],\n",
       "       [0.34947404],\n",
       "       [0.43650594],\n",
       "       [0.33981884],\n",
       "       [0.43430078],\n",
       "       [0.12070486],\n",
       "       [0.13267352],\n",
       "       [0.32062322],\n",
       "       [0.28159904],\n",
       "       [0.1584864 ],\n",
       "       [0.17930123],\n",
       "       [0.20625447],\n",
       "       [0.82678044],\n",
       "       [0.19306764],\n",
       "       [0.18882549],\n",
       "       [0.37409255],\n",
       "       [0.20162159],\n",
       "       [0.54879653],\n",
       "       [0.5506593 ],\n",
       "       [0.4438557 ],\n",
       "       [0.35174745],\n",
       "       [0.3083138 ],\n",
       "       [0.20510611],\n",
       "       [0.15484591],\n",
       "       [0.5091403 ],\n",
       "       [0.44926614],\n",
       "       [0.20280093],\n",
       "       [0.7042481 ],\n",
       "       [0.14531773],\n",
       "       [0.1454703 ],\n",
       "       [0.18665838],\n",
       "       [0.24471067],\n",
       "       [0.40219474],\n",
       "       [0.51493603],\n",
       "       [0.41678318],\n",
       "       [0.34675583],\n",
       "       [0.2847255 ],\n",
       "       [0.2817792 ],\n",
       "       [0.19154823],\n",
       "       [0.3422749 ],\n",
       "       [0.18357134],\n",
       "       [0.26733673],\n",
       "       [0.54201037],\n",
       "       [0.326956  ],\n",
       "       [0.23238543],\n",
       "       [0.48159254],\n",
       "       [0.1806046 ],\n",
       "       [0.34946847],\n",
       "       [0.3323925 ],\n",
       "       [0.28712133],\n",
       "       [0.20080177],\n",
       "       [0.3808753 ],\n",
       "       [0.17580086],\n",
       "       [0.13395666],\n",
       "       [0.27677524],\n",
       "       [0.2776645 ],\n",
       "       [0.45444804],\n",
       "       [0.4292241 ],\n",
       "       [0.2868532 ],\n",
       "       [0.30063573],\n",
       "       [0.42193395],\n",
       "       [0.6283255 ],\n",
       "       [0.2560461 ],\n",
       "       [0.21273059],\n",
       "       [0.54742825],\n",
       "       [0.17125967],\n",
       "       [0.43055782],\n",
       "       [0.3646408 ],\n",
       "       [0.43472645],\n",
       "       [0.66734815],\n",
       "       [0.28932005],\n",
       "       [0.27692702],\n",
       "       [0.5884377 ],\n",
       "       [0.6039537 ],\n",
       "       [0.1803131 ],\n",
       "       [0.58595324],\n",
       "       [0.14360256],\n",
       "       [0.5319128 ],\n",
       "       [0.41965508],\n",
       "       [0.5281917 ],\n",
       "       [0.35845917],\n",
       "       [0.490053  ],\n",
       "       [0.52385986],\n",
       "       [0.5181265 ],\n",
       "       [0.14514828],\n",
       "       [0.23949891],\n",
       "       [0.48478356],\n",
       "       [0.2810736 ],\n",
       "       [0.20160292],\n",
       "       [0.265485  ],\n",
       "       [0.24760401],\n",
       "       [0.6760812 ],\n",
       "       [0.25171053],\n",
       "       [0.33148524],\n",
       "       [0.49205196],\n",
       "       [0.25104713],\n",
       "       [0.4577479 ],\n",
       "       [0.73235303],\n",
       "       [0.6969678 ],\n",
       "       [0.6510443 ],\n",
       "       [0.27170762],\n",
       "       [0.20825902]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Make predictions\n",
    "predictions = model.predict(X_test_scaled)\n",
    "\n",
    "\n",
    "predictions\n",
    "# Optionally, you can print some predictions and actual values\n",
    "# for i in range(10):\n",
    "#     print(f'Predicted Price: {predictions[i][0]}, Actual Price: {y_test[i]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
